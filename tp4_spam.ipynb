{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amine-76/Apprentissage-Automatique/blob/main/tp4_spam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsCwB29k9xI9"
      },
      "source": [
        "# TP : Analyse de spams avec des techniques de classification bayésienne naïve\n",
        "\n",
        "Dans cet exercice, on va classer des emails comme spam ou non-spam selon une approche bayésienne naïve. L’ensemble des données est issu de 960 emails réels prétraités de la base Ling-spam (anciennement accessible à cette adresse http://csmining.org/index.php/ling-spam-datasets.html). Ces emails sont en langue anglaise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLL-fExR9xJA"
      },
      "source": [
        "## Données\n",
        "\n",
        "Les données relatives à cet exercice sont à télécharger sur le cours Eureka sous forme d’un fichier compacté zip ’Données classification bayésienne’. L’ensemble des données se divise en 700 emails exemples d’apprentissage et 260 emails exemples de test, chaque sous-ensemble étant par moitié des spams et des non-spams.\n",
        "\n",
        "Ces emails ont été pré-traités : élimination de mots non signifiants (the, and, ...) ; nombres et ponctuations supprimées ; regroupement de mots de même racine avec des terminaisons différentes (include, includes, included, ...) ; ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46-LnZJ79xJB"
      },
      "source": [
        "Dans le fichier nommé `train-features.txt`, les données des emails exemples d’apprentissage sont présentées sous la forme :\n",
        "\n",
        "    2 977 2\n",
        "    2 1481 1\n",
        "    2 1549 1\n",
        "    \n",
        "Chaque enregistrement (une ligne du fichier) comporte le numéro de l’email, le second nombre indique l’indice d’un mot dans le dictionnaire de mots utilisés pour l’analyse, et le troisième donne le nombre d’occurrences de ce mot dans l’email indiqué. Ici la première ligne précise que le mail numéro 2 a 2 occurrences du mot 977 du dictionnaire."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJYeNU559xJC"
      },
      "source": [
        "Il est à noter qu'il n'est pas utile de connaître les mots du dictionnaire dans le cadre de cet exercice.\n",
        "\n",
        "Ce fichier va permettre de créer une matrice creuse (cf.https://fr.wikipedia.org/wiki/Matrice_creuse) qui va nous permettre de calculer nos statistiques plus facilement :\n",
        "\n",
        "    numTrainDocs = 700 # nombre total d'emails exemples d’apprentissage\n",
        "    numTokens = 2500 # nombre de mots dans le dictionnaire\n",
        "    M = np.loadtxt(’train-features.txt’)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "numTrainDocs = 700 # nombre total d'emails exemples d’apprentissage\n",
        "numTokens = 2500 # nombre de mots dans le dictionnaire\n",
        "M = np.loadtxt('train-features.txt')\n",
        "print(\"M :\\n\",M)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Opn44gjJ-53V",
        "outputId": "ff2d396c-9a56-4272-d899-fa22e04d127c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "M :\n",
            " [[1.000e+00 1.900e+01 2.000e+00]\n",
            " [1.000e+00 4.500e+01 1.000e+00]\n",
            " [1.000e+00 5.000e+01 1.000e+00]\n",
            " ...\n",
            " [7.000e+02 2.479e+03 2.000e+00]\n",
            " [7.000e+02 2.481e+03 2.000e+00]\n",
            " [7.000e+02 2.500e+03 3.000e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-mnuhwL9xJC"
      },
      "source": [
        "Puis créer la matrice creuse `train_matrix` de taille (700×2500) selon la configuration suivante :\n",
        "`train_matrix[i,j]` correspond au nombre d'occurence du mot $j$ du dictionnaire dans l'email $i$.\n",
        "\n",
        "Pour finir sur ces données, il manque encore les labels associés à ces emails, qui précisent si ce sont des spams (valeur 1) ou non (valeur 0) :\n",
        "\n",
        "    train_labels = np.loadtxt(’train-labels.txt’)\n",
        "\n",
        "Cela donne un vecteur de taille(m,1) où m est le nombre d'emails exemples (c'est à dire m = `numTrainDocs`)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Création de la matrice creuse\n",
        "train_matrix = np.zeros((numTrainDocs, numTokens))\n",
        "for i in range(M.shape[0]):\n",
        "    train_matrix[int(M[i,0]-1), int(M[i,1]-1)] = M[i,2]\n",
        "print(\"train_matrix :\\n\",train_matrix)\n",
        "train_labels = np.loadtxt('train-labels.txt')\n",
        "print(\"train_labels :\\n\",train_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dppMuYZ_Jki",
        "outputId": "9a2b002d-1f48-48e4-f7aa-57f510dc6b89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_matrix :\n",
            " [[ 0.  0.  0. ...  0.  0.  0.]\n",
            " [ 0.  0.  0. ...  0.  0.  0.]\n",
            " [ 0.  0.  0. ...  0.  0.  0.]\n",
            " ...\n",
            " [ 1.  0.  0. ...  0.  0.  0.]\n",
            " [ 1.  0.  0. ...  0.  0.  0.]\n",
            " [ 3.  2. 17. ...  0.  0.  3.]]\n",
            "train_labels :\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNOOJoSU9xJC"
      },
      "source": [
        "## Méthode de classification bayésienne naïve\n",
        "La méthode utilisée ici est décrite dans [1].\n",
        "\n",
        "L'objectif est de classifier des documents par leur contenu, par exemple des emails en spam et non-spam.\n",
        "\n",
        "Les documents proviennent d'un certain nombre de classes de documents (par exemple, la classe \"spam\" et la classe \"non spam\").  \n",
        "\n",
        "Ces classes de document sont définies comme des ensembles de mots.\n",
        "\n",
        "La probabilité\n",
        "\n",
        "$$\n",
        "{\\displaystyle P(w\\vert C)}\n",
        "$$\n",
        "\n",
        "s'interprète de la manière suivante : sachant que nous sommes dans un document de classe $C$, il s'agit de la probabilité que $w$ soit présent dans ce document."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGLES4Tg9xJD"
      },
      "source": [
        "Une hypothèse forte faite ici est qu'il n'y a aucune dépendance entre la présence de mots. Autrement dit, soient 2 mots quelconques, le fait que l'un des 2 mots soit présent dans un document d'une classe donnée est indépendant du fait que l'autre mot soit présent dans un document appartemant à la même classe.  \n",
        "\n",
        "On comprend que cette hypothèse est une simplification forte qui diffère de la réalité. Il est facile d'imaginer que la présence d'un mot puisse entraîner une probabilité forte de présence d'un autre mot utilisé fréquemment en association avec le premier. La gestion de la dépendance est très complexe et difficilement quantifiable. Faire l'hypothèse de l'indépendance de la présence des mots est donc plus simple et permet de mener les calculs présentés par la suite."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MChR3zzq9xJD"
      },
      "source": [
        "On considère un document (email) D comme étant un ensemble de mots $\\{w_i; 0 \\leq i \\leq m\\}$, $m$ étant le nombre de mots de ce document.\n",
        "\n",
        "La probabilité :\n",
        "\n",
        "$$\n",
        "{\\displaystyle P(D\\vert C)=\\prod _{w_i \\in D}P(w_{i}\\vert C)}\n",
        "$$\n",
        "\n",
        "s'interprète de la manière suivante : sachant que nous sommes dans un document de classe C, il s'agit de la probabilité que tous les mots du document D puissent être présents.\n",
        "\n",
        "La question qui nous intéresse est la suivante : quelle est la probabilité qu'un document D appartienne à une classe donnée C ?  \n",
        "C'est à dire : sachant que nous avons un document D, quelle est la probabilité d'être dans C ? Ce qui se traduit par le calcul de $P(C|D)$ ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znXZv8To9xJD"
      },
      "source": [
        "Par définition,\n",
        "\n",
        "$$\n",
        "{\\displaystyle P(D\\vert C)={P(D\\cap C) \\over P(C)}}\n",
        "$$\n",
        "\n",
        "et\n",
        "\n",
        "$$\n",
        "{\\displaystyle P(C\\vert D)={P(D\\cap C) \\over P(D)}}\n",
        "$$\n",
        "\n",
        "Le théorème de Bayes nous permet d'inférer la probabilité en termes de vraisemblance.\n",
        "\n",
        "$$\n",
        "{\\displaystyle P(C\\vert D)={P(C) \\over P(D)}\\,P(D\\vert C)}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tbq4TnNX9xJE"
      },
      "source": [
        "Si on suppose qu'il n'existe que deux classes mutuellement exclusives, $S$ et $\\neg S$ (e.g. spam et non-spam), telles que chaque élément (email) appartienne soit à l'une, soit à l'autre,\n",
        "\n",
        "$$\n",
        "{\\displaystyle P(D\\vert S)=\\prod _{w_i \\in D}P(w_{i}\\vert S)\\,}\n",
        "$$\n",
        "\n",
        "et\n",
        "\n",
        "$$\n",
        "{\\displaystyle P(D\\vert \\neg S)=\\prod _{w_i \\in D}P(w_{i}\\vert \\neg S)}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "er9eNSgH9xJE"
      },
      "source": [
        "En utilisant le résultat bayésien ci-dessus, on peut écrire :\n",
        "\n",
        "$$\n",
        "{\\displaystyle P(S\\vert D)={P(S) \\over P(D)}\\,\\prod _{w_i \\in D}P(w_{i}\\vert S)}\n",
        "$$\n",
        "\n",
        "$$\n",
        "{\\displaystyle P(\\neg S\\vert D)={P(\\neg S) \\over P(D)}\\,\\prod _{w_i \\in D}P(w_{i}\\vert \\neg S)}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfcwCPcT9xJE"
      },
      "source": [
        "En divisant les deux équations, on obtient :\n",
        "\n",
        "$$\n",
        "{\\displaystyle {P(S\\vert D) \\over P(\\neg S\\vert D)}={P(S)\\,\\prod _{w_i \\in D}P(w_{i}\\vert S) \\over P(\\neg S)\\,\\prod _{w_i \\in D}P(w_{i}\\vert \\neg S)}}\n",
        "$$\n",
        "\n",
        "qui peut être factorisée de nouveau en :\n",
        "\n",
        "$$\n",
        "{\\displaystyle {P(S\\vert D) \\over P(\\neg S\\vert D)}={P(S) \\over P(\\neg S)}\\,\\prod _{w_i \\in D}{P(w_{i}\\vert S) \\over P(w_{i}\\vert \\neg S)}}\n",
        "$$\n",
        "\n",
        "Le document peut donc être classifié comme suit : il s'agit de spam si ${\\displaystyle {P(S\\vert D)\\over P(\\neg S\\vert D)} >1}$, sinon il s'agit d'un courrier normal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2cUidb29xJF"
      },
      "source": [
        "**Remarque**\n",
        "\n",
        "Il peut être efficace de calculer le logarithme népérien de ces expressions, noté $\\ln$. La raison de cette manipulation provient de la propriété des fonctions logarithmes, à savoir que le logarithme d'un produit AB est égal à la somme des logarithmes de A et de B, soit:\n",
        "\n",
        "$$\n",
        "\\ln(AB) = \\ln(A)+\\ln(B)\n",
        "$$\n",
        "\n",
        "Ce qui va permettre de transformer le produit de la formule précédente en une somme qui est plus facile à calculer à partir des éléments extraits des tableaux.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83QpX26p9xJF"
      },
      "source": [
        "Voici les détails des calculs en effectuant cette manipulation :\n",
        "\n",
        "$$\n",
        "{\\displaystyle \\ln\\left({P(S\\vert D) \\over P(\\neg S\\vert D)}\\right)=\\ln \\left({P(S) \\over P(\\neg S)}\\,\\prod _{w_i \\in D}{P(w_{i}\\vert S) \\over P(w_{i}\\vert \\neg S)}\\right)}\n",
        "$$\n",
        "\n",
        "$$\n",
        "{\\displaystyle \\ln\\left({P(S\\vert D) \\over P(\\neg S\\vert D)}\\right)=\\ln \\left({P(S) \\over P(\\neg S)}\\right) + \\sum _{w_i \\in D} \\ln \\left({P(w_{i}\\vert S) \\over P(w_{i}\\vert \\neg S)}\\right)}\n",
        "$$\n",
        "\n",
        "\n",
        "$$\n",
        "{\\displaystyle\n",
        "\\ln\\left({P(S\\vert D) \\over P(\\neg S\\vert D)}\\right)=\n",
        "\\ln(P(S))-\\ln(P(\\neg S))+\\sum_{w_i \\in D}{\\left( \\ln(P(w_{i}\\vert S)-\\ln(P(w_{i}\\vert \\neg S) \\right)}\n",
        "}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLk5MqY19xJF"
      },
      "source": [
        "Sachant que $\\ln 1 = 0$, le test qui permet de détection de spam qui consiste à vérifier que\n",
        "${\\displaystyle {P(S\\vert D)\\over P(\\neg S\\vert D)} >1}$\n",
        "s'écrira ici\n",
        "${\\displaystyle \\ln\\left({P(S\\vert D)\\over P(\\neg S\\vert D)}\\right) > 0}$.\n",
        "\n",
        "Et donc il faut tester si le membre droit de l'égalité est positif."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sfuZ9Sr9xJF"
      },
      "source": [
        "## Implémentation\n",
        "\n",
        "Les fichiers `train-features.txt` et `train-labels.txt` servent de données d'apprentissage permettant de calculer les valeurs de ${\\displaystyle P(w_{i}\\vert S)}$ et de ${\\displaystyle P(w_{i} \\vert \\neg S)}$.\n",
        "\n",
        "On charge ensuite le fichier `test-features.txt` contenant les 260 emails de test puis on classera chacun de ces mails en spam ou courrier normal à partir de la technique précédente.\n",
        "\n",
        "On compare ensuite le résultat de la classification avec la classification réelle de ces emails de test que l'on trouve dans le fichier `test-labels.txt`. On représentera pour cela une matrice de confusion permettant de représenter sous forme matricielle le nombre de vrai-positif, faux-positif, vrai-négatif et faux-négatif.\n",
        "\n",
        "En s'inspirant du code python fourni dans le polycopié \"Matrice de confusion\", re-écrire le calcul de classification et de représentation de la matrice de confusion en utilisant la méthode `GaussianNB`de la bibliothèque `sklearn.naive_bayes` et comparer les résultats obtenus avec ceux que vous avez calculés précédemment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIyRfh759xJG"
      },
      "source": [
        "**Indications**\n",
        "\n",
        "A partir des données d'apprentissage, on calcule facilement $P(S)$ comme étant le nombre de $1$ dans le fichier `train-labels.txt` que l'on note $N_S$, divisé par le nombre d'éléments dans ce fichier, noté $N$. De même\n",
        "${\\displaystyle P(\\neg S) = N_{\\neg S}/N}$ où $N_{\\neg S}$ est le nombre de $0$ dans le fichier `train-labels.txt`.\n",
        "\n",
        "Comment calculer $P(w_i \\vert S)$ ?\n",
        "\n",
        "$w_i$, ième mot d'un document, correspond à un des mots référencé du dictionnaire, par exemple, on suppose que c'est le mot d'indice $j$ du dictionnaire. Il suffit alors de compter dans la matrice contruite précédemment, le nombre de valeurs non nulles dans la colonne $j$ pour tous les mails qui sont considérés comme des spams (c'est à dire `train_labels[i]=1` pour le mail de la ligne $i$). Et on divise ce nombre par $N_S$ pour avoir la probabilité sachant $S$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCcbWIBb9xJG"
      },
      "source": [
        "Dans cette méthode, le nombre d'occurence des mots dans un mail n'intervient pas (on pourra réfléchir à savoir comment le faire intervenir en extension de cet exercice) et donc on a intérêt à remplacer dans la matrice toutes les valeurs non nulles par des 1. Ainsi on pourra simplifier le calcul de la manière suivante :\n",
        "\n",
        "$$\n",
        "{\\displaystyle\n",
        "P(w_i \\vert S) = \\frac{\\sum_{k=1}^{m} \\left(M[k,j]\\, T[k]\\right)}{N_S}\n",
        "= \\frac{\\sum_{k=1}^{m} \\left(M[k,j]\\, T[k]\\right)}{\\sum_{k=1}^{m} T[k]}\n",
        "}\n",
        "$$\n",
        "\n",
        "où $w_i$ est le mot $j$ du dictionnaire, $m$ est le nombre d'emails dans la base d'apprentissage, $M$ est la matrice `train_matrix`, construite précédemment et $T$ correspond au vecteur `train_labels`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQ58wzC-9xJG"
      },
      "source": [
        "**Référence**\n",
        "- [article wikipedia \"Classification naïve bayésienne\"](https://fr.wikipedia.org/wiki/Classification_na%C3%AFve_bay%C3%A9sienne)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VkXDCla9xJG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddd84d7d-c13f-48db-a308-2464c0b38070"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================\n",
            "--- RÉSULTATS DE VOTRE MODÈLE NAIVE BAYES (Log-Ratio) ---\n",
            "=========================================================\n",
            "Matrice de Confusion:\n",
            "[[125   5]\n",
            " [  0 130]]\n",
            "\n",
            "Précision (Accuracy) de Votre Modèle : 0.9808\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import numpy as np # Ajouté pour les opérations NumPy manquantes dans la version originale\n",
        "from sklearn.metrics import confusion_matrix # Ajouté car utilisé dans la version originale\n",
        "\n",
        "# --- Constantes pour le Lissage de Laplace ---\n",
        "alpha = 1\n",
        "V = numTokens # Taille du vocabulaire (2500)\n",
        "# Note: numTrainDocs et numTokens doivent être définis précédemment\n",
        "\n",
        "# --- Calcul des Probabilités A Priori ---\n",
        "\n",
        "# Correction: La boucle pour N_no_spam doit aller jusqu'à numTrainDocs (indice 699)\n",
        "N_spam = 0\n",
        "for i in range(numTrainDocs):\n",
        "    if train_labels[i] == 1:\n",
        "            N_spam += 1\n",
        "print(\"N_spam:\",N_spam)\n",
        "\n",
        "N_no_spam = 0\n",
        "for i in range(numTrainDocs): # Correction de la boucle : numTrainDocs\n",
        "    if train_labels[i] == 0:\n",
        "            N_no_spam += 1\n",
        "print(\"N_no_spam:\",N_no_spam)\n",
        "\n",
        "def Prob_S(N_spam,numDocs):\n",
        "  return N_spam/numDocs\n",
        "\n",
        "def Prob_no_S(N_no_spam,numDocs):\n",
        "  return N_no_spam/numDocs\n",
        "\n",
        "# --- Fonctions de Probabilité Conditionnelle (CORRIGÉES) ---\n",
        "\n",
        "# Calcule P(Wj | S)\n",
        "def prob_mot_spam(train_matrix, train_labels, j):\n",
        "  nb_occurence = 0\n",
        "  # NOTE: C'EST ICI QUE L'ERREUR ÉTAIT (numTrainDocs = 700)\n",
        "  for i in range(numTrainDocs):\n",
        "    if train_labels[i] == 1 and train_matrix[i,j] > 0:\n",
        "      nb_occurence += 1\n",
        "\n",
        "  # Correction Mathématique: Lissage de Laplace\n",
        "  return (nb_occurence + alpha) / (N_spam + alpha * V)\n",
        "\n",
        "# Calcule P(Wj | non S)\n",
        "def prob_mot_no_spam(train_matrix, train_labels, j):\n",
        "  nb_occurence = 0\n",
        "  for i in range(numTrainDocs):\n",
        "    if train_labels[i] == 0 and train_matrix[i,j] > 0:\n",
        "      nb_occurence += 1\n",
        "\n",
        "  # Correction Mathématique: Lissage de Laplace\n",
        "  return (nb_occurence + alpha) / (N_no_spam + alpha * V)\n",
        "\n",
        "\n",
        "# --- Fonction Ratio (Forme Produit) ---\n",
        "def ratio(document_vector, N_spam,numDocs,matrice,labels):\n",
        "\n",
        "  # Terme a priori: P(S) / P(¬S)\n",
        "  produit = Prob_S(N_spam,numDocs) / Prob_no_S(N_no_spam,numDocs)\n",
        "\n",
        "  # Terme de vraisemblance (Produit des ratios conditionnels)\n",
        "  for j in range(numTokens):\n",
        "\n",
        "      # Filtrer pour n'inclure que les mots PRÉSENTS\n",
        "      if document_vector[j] > 0:\n",
        "\n",
        "          # Les fonctions prob_mot_spam/no_spam appellent ici la matrice de test\n",
        "          # MAIS elles utilisent numTrainDocs (700) dans leur boucle interne\n",
        "          P_w_sachant_S = prob_mot_spam(matrice,labels, j)\n",
        "          P_w_sachant_no_S = prob_mot_no_spam(matrice, labels, j)\n",
        "\n",
        "          # Multiplier par le ratio du mot j\n",
        "          produit *= P_w_sachant_S / P_w_sachant_no_S\n",
        "\n",
        "  return produit\n",
        "\n",
        "def docIsSpam(ratio_calcule):\n",
        "# En forme produit, le seuil de décision est 1\n",
        "  if ratio_calcule > 1:\n",
        "    print(f\"Ratio :{ratio_calcule} > 1\")\n",
        "    print(\"Le document est un spam\")\n",
        "    return True\n",
        "  else:\n",
        "    print(f\"Ratio :{ratio_calcule} < 1\")\n",
        "    print(\"Le document n'est pas un spam\")\n",
        "    return False\n",
        "\n",
        "# --- Test ---\n",
        "test_features = np.loadtxt('test-features.txt')\n",
        "test_labels = np.loadtxt('test-labels.txt')\n",
        "numTrainDocs_test = 260\n",
        "numTokens_test = 2500\n",
        "M_test = np.loadtxt('test-features.txt')\n",
        "test_matrix = np.zeros((numTrainDocs_test, numTokens_test))\n",
        "test_labels = np.loadtxt('test-labels.txt')\n",
        "\n",
        "for i in range(M_test.shape[0]):\n",
        "    test_matrix[int(M_test[i,0]-1), int(M_test[i,1]-1)] = M_test[i,2]\n",
        "\n",
        "print(\"test_matrix :\\n\",test_matrix)\n",
        "print(\"test_labels :\\n\",test_labels)\n",
        "\n",
        "N_spam_test = 0\n",
        "for i in range(numTrainDocs_test):\n",
        "    if test_labels[i] == 1:\n",
        "            N_spam_test += 1\n",
        "print(\"N_spam_test:\",N_spam_test)\n",
        "\n",
        "N_no_spam_test = 0\n",
        "for i in range(numTrainDocs_test): #\n",
        "    if test_labels[i] == 0:\n",
        "            N_no_spam_test += 1\n",
        "print(\"N_no_spam_test:\",N_no_spam_test)\n",
        "\n",
        "for i in range(numTrainDocs_test):\n",
        "  # CET APPEL EST LA SOURCE DE L'INDEXERROR\n",
        "  ratio_calcule = ratio(test_matrix[i], N_spam_test,numTrainDocs_test,test_matrix,test_labels)\n",
        "  docIsSpam(ratio_calcule)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}